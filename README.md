# Evaluating and Improving the Robustness of Security Functions Generated by LLMs

This repository contains all the code related to the paper "Evaluating and Improving the Robustness of Security Functions Generated by LLMs" submitted at ICSE 2025.

This work addresses the critical issue of evaluating and improving the robustness of LLM-generated security functions.  The approach integrates Retrieval Augmented Generation (RAG) and Self-Ranking into the prompting process. RAG enhances the security of the output by incorporating external knowledge sources, while the novel Self-Ranking technique, inspired by the concept of Self-Consistency, generates multiple reasoning paths and creates ranks to select the most secure code.

In the page [Artifacts](docs/artifacts.md) you can find the guide to download the artifacts with their accurate description.

[Results](docs/results.md) reportes an extension of the analysis of the results reported in the submitted paper, taking into account the *accuracy* in addition of the *F2* considered as the main metric in the paper.

The following paragraphs will provide a guide to reproduct our experiments.